# Instrucciones

1. `docker compose up -d`
2. http://localhost:8501/ -> JupyterLab
3. http://localhost:8502/ -> Streamlit

# Estructura

```bash
├── Dockerfile
├── LICENSE
├── README
├── app
│   ├── db
│   │   ├── csv                           # Original data
│   │   ├── csv_clean                     # Data cleaned
│   │   ├── sqlite                        # Base de datos
│   │   └── us-states.json                # GeoPandas
│   └── src
│       ├── data_cleaning_train.ipynb     # Script de limpieza
│       ├── models                        # Pesos
│       ├── streamlit                     # Código del dashboard
│       ├── test                          # Data processed
│       └── train.ipynb                   # Jupyter para entrenamientos
├── docker-compose.yaml
└── requirements.txt
```

Recomiendo mirar el `data_cleaning_train.ipynb` para mirar la limpieza y `train.ipynb` de cara a los entrenamientos. Para revisar los plots lo mejor es mirar el dashboard de streamlit.

En el caso de querer ejecutar el `data_cleaning_train.ipynb` hay que asegurarse de que todos los zips correspondientes a los CSVs estén descomprimidos en la carpeta `app/db/csv` y que el `.sqlite3` también lo este.
